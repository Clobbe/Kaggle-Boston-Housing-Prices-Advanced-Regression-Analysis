---
title: "Kaggle Project : Boston Housing - Advanced Regression Techniques"
author: "Clobbe Norman"
date: "11/19/2017"
output: github_document
---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE)
```

# 1.What are we dealing with?
Need to clean up this bulletlist later + write an introduction to the case and thank Pedro Marcelino for the inspiration and [guidance on his approach to this project](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python)


1. **Understand the problem**
We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.*

2. **Univariable study**
We'll just focus on the dependent variable ('SalePrice') and try to know a little bit more about it.

3. **Multivariate study**
We'll try to understand how the dependent variable and independent variables relate.

4. **Basic cleaning**
We'll clean the dataset and handle the missing data, outliers and categorical variables.

5. **Test assumptions**
We'll check if our data meets the assumptions required by most multivariate techniques.

## Pick up the right toolset

Meaning, importing the goodies from `tidyverse` for easy data wrangling, `ggplot2` for some nice visualization and `broom` for making sure we don't miss anything while creating our models later on.

```{r echo=FALSE}
require(ggplot2)
require(tidyverse)
```

```{r }
df.test.raw <- read_csv('test.csv', col_names = T)
df.train.raw <- read_csv('train.csv', col_names = T)

df.test <- df.test.raw
df.train <- df.train.raw
```

Now let's have a look at the the data that we loaded into R.


```{r }
df.train %>% 
  glimpse()

```

Wow!
That's impressive - 1,460 observations and 81 variables.

From this quick overview of the dataset it seems like R interpret all the text varibles as `<chr>`, character variables. Something which will mess up later when we want to build our model and doing some visualization.

Let's fix that by turning these characters into proper factors with levels instead.


```{r }
df.test <- df.test %>% 
  unclass() %>% 
  as.data.frame()

df.train <- df.train %>% 
  unclass() %>% 
  as.data.frame()
```

Let's have a look now again at the variables.

```{r }
df.train %>%
  glimpse()

```



##Let's look at the variables
```{r }
df.train %>% 
  colnames() %>% 
  sort()
```
We did some variable evaluation, tidious but very useful. It was done in a regular [Google Spreadsheet.](https://docs.google.com/spreadsheets/d/16RMnBO7TQLbaJIiphSrcFAlJq7ewtXyojskUUsE__FM/edit?usp=sharing)

From the initial evaluation with determine that some variables are more interesting for houses and some for apartment houses. 

By following the recommendation from previous author we grouped variables into the three categories:

* `building`

* `location`

* `space`

We then also evaluated how much influence each variable would have on the price. Classifying each variable with an expectation of either `Hi`, `Med` or `Low` influence.

The problem is getting more and more tangible and now it's just about validating wether the selected variables indeed are positive correlated with an increase in price. 

```{r echo = FALSE }

#setting which columns to filter out from the main dataset
expectation.hi <- c("Neighborhood","Condition1","OverallQual",
                    "OverallCond","YearBuilt","YearRemodAdd",
                    "TotRmsAbvGrd","Fireplaces","YrSold","SalePrice")
```


To get the overview and find which variables that correlate with increased price it's convenient to do a matrix of plot who just take care of everything and give us an image with everything we're interested in. 

```{r echo = FALSE, eval= FALSE }
df.train.hi <- df.train %>% select(expectation.hi)
df.train.med <- df.train %>% select(expectation.med)

require(GGally)
ggpairs(df.train.hi, cardinality_threshold = 25)
```

###Variables expected to have 'Hi' influence
![Correlation matrix plot for hi influence variables](https://dl.dropboxusercontent.com/s/bry1ahaxnyu1s2c/Screenshot%202017-11-25%2023.08.43.png)
Looks like some of the variables we expected to have high influence are positively correlated with the price. The highlighted variables are:

*  `OverallQual` (*perhaps the most fluffy variable in this dataset - the overall quality of materials and finish*)

*  `YearBuilt` (*the year when the house was built*)

*  `YearRemodAdd` (*the year when the house last was remodule*)

*  `TotRmsAbvGrd` (*the number of rooms above grade (bathrooms not included)*)


#2.What does target varible `SalePrice` look like

The scope for this project is to build a model that from a set of variables (which we're currently trying to find) will be the basis for a model which in turn can predict the price - SalePrice.


Let's find out what we know about `SalePrice`. 

```{r }
df.train %>% 
  select(SalePrice) %>% 
  summary()
```

###First off - this looks perfect!

There's no zero's, meaning that the variable don't have any outliers that could later on affect our model.

Let's have a look at the distribution of `SalePrice`.

```{r}
df.train %>% 
  ggplot(aes(x = SalePrice)) +
  geom_histogram(
      aes(y = ..density..),
      fill = 'blue',
      alpha = 0.4) +
  geom_density(alpha = 0, size = 1)
```

Seems like we're dealing with a right skewed distribution, meaning it's deviating from a good ole normal distribution.

Let's find out just how skewed the distribution is.

```{r echo = TRUE}
require(moments)

df.train %>% 
  select(SalePrice) %>% 
  summarise(
      Skewness = skewness(SalePrice),
      Kurtosis = kurtosis(SalePrice)
  )
```

#Let's dig deeper into the relationship

So up until now we've only looked at the relationship between `SalePrice` and numeric variables. What about the categorical variable `OverallQual`? We already know that's it's related with `SalePrice` but not how much.

```{r echo = FALSE}
require(RColorBrewer)
colors <- brewer.pal(11, 'Spectral')
```

```{r}
df.train %>% 
  ggplot(aes(x = as.factor(OverallQual), y = SalePrice, fill = as.factor(OverallQual))) + 
    geom_boxplot(outlier.alpha = 0.3,
                 outlier.stroke = 0.5) +
  
    theme(panel.grid.major = element_blank(),
          legend.position="none") +
    
  xlab('OverallQual')
```

Well, this is nothing new but now we know how the `Overall Quality` is associated with `SalePrice`


Let's dig deeper on the second categorical variable 

```{r}

df.train %>% 
  ggplot(aes(x = as.factor(YearBuilt), y = SalePrice, fill = as.factor(YearBuilt))) + 
    geom_boxplot(alpha = 0.8,
                 outlier.alpha = 0.6,
                 position = 'jitter',
                 color = NA) +
  
    geom_smooth(aes(group=1),
                method = "lm",
                se=FALSE,
                color="black") +
  
  theme(panel.grid.major = element_blank(),
        legend.position="none",
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) +
  
  xlab('YearBuilt')

```

####Nice colors! But what does it tell us?

As seen above the black trendline helps us to determine that there is a positive association between `SalePrice` and variable `YearBuilt`. 



###So to sum things up…

We've now found that:

* `YearBuilt`, `OverallQual`, `YearRemodAdd` and `TotRmsAbvGrd` are all variables that's lineraly related with `SalePrice` .


> *"But, hey! That's only 4 variables out of 81 available. Don't you miss out on a lot of potential variables that could have siginificant affect on the target?"*

In Pedro's guide he refer to that the trick for this particular case seems to be `variable selction` rather than `variable engineering`. Which seems intutively right when you think about it since we're given 81 where most of them could be variables that describe the sale price of a house (goingin through and evaluating the variables in a spreadsheet).

So far the selection of variables was based soley on intuition. Next we'll approach the problem more objectively. 


#3. 

```{r}
använd detta för att mappa en lm() för alla variabler för att sen kunna sortera dom enkelt dplyr-style
library(tidyr)
library(purrr)

# Perform a linear regression on each item in the data column
by_year_country %>%
  nest(-country) %>%
  mutate(model = map(data, ~ lm(percent_yes ~ year, . )))
  mutate(tidied = tidy(model))

#exempel på hur gather funkar => riktigt användbart!
  votes_gathered <- votes_joined %>%
  gather(topic, has_topic, me:ec) %>%
  filter(has_topic == 1)

  # Filter for only the slope terms
slope_terms <- country_coefficients %>%
  filter(term == "year") %>%
  mutate(p.adjusted = p.adjust(p.value))

# Add p.adjusted column, then filter
slope_terms %>%
  filter(p.adjusted < 0.05)

```